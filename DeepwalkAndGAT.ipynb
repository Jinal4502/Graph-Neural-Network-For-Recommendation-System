{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc997f85-6ef4-477b-bc70-14dbb5dce6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import joblib\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\arodi\\\\Downloads\\\\Master_CSV(in).csv\", low_memory=False)\n",
    "\n",
    "original_graph = nx.Graph()\n",
    "total_rows = df.shape[0]\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    company_id = f\"company_{row['Global_Id']}\"\n",
    "    original_graph.add_node(company_id, bipartite='company', label=row.get(\"Name\", \"\"))\n",
    "\n",
    "    for i in range(1, 51):\n",
    "        col_name = f\"Process_Capability_{i}\"\n",
    "        capability = row.get(col_name)\n",
    "\n",
    "        if pd.notna(capability) and str(capability).strip():\n",
    "            capability_node = f\"pc_{capability}\"\n",
    "            original_graph.add_node(capability_node, bipartite='capability')\n",
    "            original_graph.add_edge(company_id, capability_node)\n",
    "\n",
    "    if idx % 1000 == 0 or idx == total_rows - 1:\n",
    "        print(f\"[INFO] Processed {idx + 1}/{total_rows} rows\")\n",
    "\n",
    "joblib.dump(original_graph, \"original_graph.pkl\")\n",
    "print(\"Graph saved as original_graph.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a850f0b-1cf5-4f12-b5e4-d37fa01c0456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from karateclub import DeepWalk\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "print(\"[INFO] Loading CSV and constructing graph...\")\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\arodi\\\\Downloads\\\\Master_CSV(in).csv\",low_memory=False)\n",
    "original_graph = nx.Graph()\n",
    "total_rows = df.shape[0]\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    company_id = f\"company_{row['Global_Id']}\"\n",
    "    original_graph.add_node(company_id, bipartite='company', label=row.get(\"Name\", \"\"))\n",
    "\n",
    "    for i in range(1, 51):\n",
    "        col_name = f\"Process_Capability_{i}\"\n",
    "        capability = row.get(col_name)\n",
    "\n",
    "        if pd.notna(capability) and str(capability).strip():\n",
    "            capability_node = f\"pc_{capability}\"\n",
    "            original_graph.add_node(capability_node, bipartite='capability')\n",
    "            original_graph.add_edge(company_id, capability_node)\n",
    "\n",
    "    if idx % 1000 == 0 or idx == total_rows - 1:\n",
    "        print(f\"[INFO] Processed {idx + 1}/{total_rows} rows\")\n",
    "\n",
    "print(\"reindex nodes\")\n",
    "node_list = list(original_graph.nodes())\n",
    "name_to_id = {name: i for i, name in enumerate(node_list)}\n",
    "id_to_name = {i: name for name, i in name_to_id.items()}\n",
    "\n",
    "G = nx.relabel_nodes(original_graph, name_to_id)\n",
    "\n",
    "print(\"deepwalk train\")\n",
    "start_time = time.time()\n",
    "\n",
    "model = DeepWalk(walk_number=10, walk_length=80, dimensions=64, window_size=5, workers=4)\n",
    "model.fit(G)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"training completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "joblib.dump(model, \"deepwalk_model.pkl\")\n",
    "\n",
    "embeddings = model.get_embedding()\n",
    "embedding_dict = {id_to_name[i]: embeddings[i] for i in range(len(embeddings))}\n",
    "joblib.dump(embedding_dict, \"deepwalk_embeddings_dict.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "296e4438-59b0-4c9a-8e07-d2bccd0a36a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link Prediction ROC-AUC: 0.2653\n",
      "link Prediction Average Precision: 0.4389\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "embedding_dict = joblib.load(\"deepwalk_embeddings_dict.pkl\")\n",
    "all_nodes = list(embedding_dict.keys())\n",
    "\n",
    "original_graph = joblib.load(\"original_graph.pkl\")\n",
    "\n",
    "all_edges = list(original_graph.edges())\n",
    "random.shuffle(all_edges)\n",
    "split_idx = int(0.8 * len(all_edges))\n",
    "train_edges = all_edges[:split_idx]\n",
    "test_edges = all_edges[split_idx:]\n",
    "\n",
    "train_graph = nx.Graph()\n",
    "train_graph.add_nodes_from(original_graph.nodes(data=True))\n",
    "train_graph.add_edges_from(train_edges)\n",
    "\n",
    "def generate_negative_edges(G, num_samples):\n",
    "    neg_edges = set()\n",
    "    while len(neg_edges) < num_samples:\n",
    "        u, v = random.sample(all_nodes, 2)\n",
    "        if not G.has_edge(u, v) and u != v:\n",
    "            neg_edges.add((u, v))\n",
    "    return list(neg_edges)\n",
    "\n",
    "negative_test_edges = generate_negative_edges(original_graph, len(test_edges))\n",
    "\n",
    "def edge_similarity(u, v, embeddings):\n",
    "    return cosine_similarity([embeddings[u]], [embeddings[v]])[0][0]\n",
    "\n",
    "y_true = []\n",
    "y_score = []\n",
    "#here we are doing link validation\n",
    "for u, v in test_edges:\n",
    "    if u in embedding_dict and v in embedding_dict:\n",
    "        sim = edge_similarity(u, v, embedding_dict)\n",
    "        y_true.append(1)\n",
    "        y_score.append(sim)\n",
    "\n",
    "for u, v in negative_test_edges:\n",
    "    if u in embedding_dict and v in embedding_dict:\n",
    "        sim = edge_similarity(u, v, embedding_dict)\n",
    "        y_true.append(0)\n",
    "        y_score.append(sim)\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_score)\n",
    "ap_score = average_precision_score(y_true, y_score)\n",
    "\n",
    "print(f\"link Prediction ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"link Prediction Average Precision: {ap_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53965ded-fb80-4eb0-88ac-5811892f9ba4",
   "metadata": {},
   "source": [
    "Above was a naive attempt at using deepwalk to learn embeddings and to see if it can distinguish positive/negative edges. This was poor performance but was not expanded much off of.\n",
    "\n",
    "As for below we are creating a graph autoencoder using the graph attention network to learn embeddings through attention. This has superior performance and is a good direction for link prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7705e644-58ae-4373-8096-6c34b72ec3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build graph\n",
      "nodes 21212, edges 65285\n",
      "converting data\n",
      "x shape torch.Size([21212, 2])\n",
      "edge ind shape torch.Size([2, 130570])\n",
      "randomlinksplit\n",
      "edge index shape torch.Size([2, 104458])\n",
      "positive label 52229\n",
      "negative labels 52229\n",
      "val pos 6528, neg 6528\n",
      "test pos 6528, neg 6528\n",
      "GAT‑GAE model definition\n",
      "training\n",
      "epoch 01 loss 1.4469\n",
      "epoch 10 loss 1.3372\n",
      "epoch 20 loss 1.1706\n",
      "epoch 30 loss 1.1282\n",
      "epoch 40 loss 1.1104\n",
      "epoch 50 loss 1.1025\n",
      "epoch 60 loss 1.0976\n",
      "epoch 70 loss 1.0927\n",
      "epoch 80 loss 1.0815\n",
      "epoch 90 loss 1.0224\n",
      "epoch 100 loss 0.9999\n",
      "epoch 110 loss 0.9901\n",
      "epoch 120 loss 0.9806\n",
      "epoch 130 loss 0.9722\n",
      "epoch 140 loss 0.9638\n",
      "epoch 150 loss 0.9531\n",
      "epoch 160 loss 0.9401\n",
      "epoch 170 loss 0.9264\n",
      "epoch 180 loss 0.9062\n",
      "epoch 190 loss 0.8865\n",
      "epoch 200 loss 0.8755\n",
      "validation on 10% of data\n",
      "\n",
      "Link‑prediction ROC‑AUC:       0.9867\n",
      "Link‑prediction Avg Precision:  0.9866\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.nn import GAE, GATConv\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "print(\"build graph\")\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\arodi\\\\Downloads\\\\Master_CSV(in).csv\",\n",
    "                 low_memory=False)\n",
    "G = nx.Graph()\n",
    "for _, row in df.iterrows():\n",
    "    comp = f\"company_{row['Global_Id']}\"\n",
    "    G.add_node(comp, bipartite=0)\n",
    "    for i in range(1, 51):\n",
    "        cap = row.get(f\"Process_Capability_{i}\")\n",
    "        if pd.notna(cap) and cap.strip():\n",
    "            pc = f\"pc_{cap}\"\n",
    "            G.add_node(pc, bipartite=1)\n",
    "            G.add_edge(comp, pc)\n",
    "print(f\"nodes {G.number_of_nodes()}, edges {G.number_of_edges()}\")\n",
    "\n",
    "#convert to pyg with one-hot features\n",
    "print(\"converting data\")\n",
    "feat = {\n",
    "    n: [1, 0] if d['bipartite'] == 0 else [0, 1]\n",
    "    for n, d in G.nodes(data=True)\n",
    "}\n",
    "nx.set_node_attributes(G, feat, 'x')\n",
    "data = from_networkx(G)\n",
    "data.x = data.x.float()\n",
    "print(f\"x shape {data.x.shape}\")\n",
    "print(f\"edge ind shape {data.edge_index.shape}\")\n",
    "\n",
    "print(\"randomlinksplit\")\n",
    "split = RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    is_undirected=True, \n",
    "    split_labels=True, \n",
    "    add_negative_train_samples=True,\n",
    "    neg_sampling_ratio=1.0\n",
    ")\n",
    "train_data, val_data, test_data = split(data)\n",
    "\n",
    "print(f\"edge index shape {train_data.edge_index.shape}\")\n",
    "print(f\"positive label {train_data.pos_edge_label_index.shape[1]}\")\n",
    "print(f\"negative labels {train_data.neg_edge_label_index.shape[1]}\")\n",
    "print(f\"val pos {val_data.pos_edge_label_index.shape[1]}, neg {val_data.neg_edge_label_index.shape[1]}\")\n",
    "print(f\"test pos {test_data.pos_edge_label_index.shape[1]}, neg {test_data.neg_edge_label_index.shape[1]}\")\n",
    "\n",
    "print(\"GAT‑GAE model definition\")\n",
    "class GATEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=4):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1)\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GAE(GATEncoder(\n",
    "    in_channels=data.x.size(1),\n",
    "    hidden_channels=32,\n",
    "    out_channels=16,\n",
    "    heads=4\n",
    ")).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "train_data = train_data.to(device)\n",
    "\n",
    "print(\"training\")\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "    loss = model.recon_loss(\n",
    "        z,\n",
    "        train_data.pos_edge_label_index,\n",
    "        train_data.neg_edge_label_index\n",
    "    )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train_one_epoch()\n",
    "    if epoch == 1 or epoch % 10 == 0:\n",
    "        print(f\"epoch {epoch:02d} loss {loss:.4f}\")\n",
    "\n",
    "print(\"validation on 10% of data\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = model.encode(data.x.to(device), data.edge_index.to(device))\n",
    "\n",
    "    pos_scores = model.decoder(z,test_data.pos_edge_label_index.to(device)).view(-1).cpu()\n",
    "    neg_scores = model.decoder(z,test_data.neg_edge_label_index.to(device)).view(-1).cpu()\n",
    "\n",
    "    y_true  = torch.cat([torch.ones_like(pos_scores),torch.zeros_like(neg_scores)]).numpy()\n",
    "    y_score = torch.cat([pos_scores, neg_scores]).numpy()\n",
    "\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "    ap      = average_precision_score(y_true, y_score)\n",
    "    print(f\"\\nLink‑prediction ROC‑AUC:       {roc_auc:.4f}\")\n",
    "    print(f\"Link‑prediction Avg Precision:  {ap:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
